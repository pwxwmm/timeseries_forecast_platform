# éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•éƒ¨ç½²æ—¶é—´åºåˆ—é¢„æµ‹å¹³å°ã€‚

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd timeseries_forecast_platform

# è¿è¡Œå¯åŠ¨è„šæœ¬
./start.sh
```

å¯åŠ¨è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æŸ¥ç¯å¢ƒä¾èµ–
- åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
- å®‰è£…ä¾èµ–
- å¯åŠ¨åç«¯å’Œå‰ç«¯æœåŠ¡

### æ‰‹åŠ¨éƒ¨ç½²

#### 1. åç«¯éƒ¨ç½²

```bash
cd backend

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# é…ç½®ç¯å¢ƒ
cp config.example.yaml config.yaml
# ç¼–è¾‘ config.yaml æ–‡ä»¶

# å¯åŠ¨æœåŠ¡
python app.py
```

#### 2. å‰ç«¯éƒ¨ç½²

```bash
cd frontend

# å®‰è£…ä¾èµ–
npm install

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# æˆ–æ„å»ºç”Ÿäº§ç‰ˆæœ¬
npm run build
npm run preview
```

## ğŸ³ Docker éƒ¨ç½²

### ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

### å•ç‹¬æ„å»ºé•œåƒ

```bash
# æ„å»ºåç«¯é•œåƒ
cd backend
docker build -t timeseries-forecast-backend .

# æ„å»ºå‰ç«¯é•œåƒ
cd frontend
docker build -t timeseries-forecast-frontend .

# è¿è¡Œå®¹å™¨
docker run -d -p 8000:8000 timeseries-forecast-backend
docker run -d -p 3000:80 timeseries-forecast-frontend
```

## â˜ï¸ äº‘å¹³å°éƒ¨ç½²

### AWS éƒ¨ç½²

#### ä½¿ç”¨ ECS

1. åˆ›å»º ECR ä»“åº“
2. æ¨é€é•œåƒåˆ° ECR
3. åˆ›å»º ECS ä»»åŠ¡å®šä¹‰
4. åˆ›å»º ECS æœåŠ¡

```bash
# æ„å»ºå¹¶æ¨é€é•œåƒ
aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin <account>.dkr.ecr.us-west-2.amazonaws.com

docker build -t timeseries-forecast-backend ./backend
docker tag timeseries-forecast-backend:latest <account>.dkr.ecr.us-west-2.amazonaws.com/timeseries-forecast-backend:latest
docker push <account>.dkr.ecr.us-west-2.amazonaws.com/timeseries-forecast-backend:latest
```

#### ä½¿ç”¨ Elastic Beanstalk

1. åˆ›å»º `.ebextensions` é…ç½®
2. ä½¿ç”¨ EB CLI éƒ¨ç½²

```bash
eb init
eb create production
eb deploy
```

### Google Cloud éƒ¨ç½²

#### ä½¿ç”¨ Cloud Run

```bash
# æ„å»ºé•œåƒ
gcloud builds submit --tag gcr.io/PROJECT-ID/timeseries-forecast-backend ./backend

# éƒ¨ç½²åˆ° Cloud Run
gcloud run deploy --image gcr.io/PROJECT-ID/timeseries-forecast-backend --platform managed --region us-central1
```

### Azure éƒ¨ç½²

#### ä½¿ç”¨ Container Instances

```bash
# æ„å»ºé•œåƒ
az acr build --registry <registry-name> --image timeseries-forecast-backend ./backend

# åˆ›å»ºå®¹å™¨å®ä¾‹
az container create --resource-group <resource-group> --name timeseries-backend --image <registry-name>.azurecr.io/timeseries-forecast-backend:latest --ports 8000
```

## ğŸ”§ ç”Ÿäº§ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡

```bash
# åç«¯ç¯å¢ƒå˜é‡
export PROMETHEUS_URL=http://prometheus:9090
export PUSHGATEWAY_URL=http://pushgateway:9091
export LOG_LEVEL=INFO
export DEBUG=false

# å‰ç«¯ç¯å¢ƒå˜é‡
export VITE_API_BASE_URL=https://api.yourdomain.com
```

### æ•°æ®åº“é…ç½®

ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ PostgreSQL æˆ– MySQL æ›¿ä»£ JSON æ–‡ä»¶å­˜å‚¨ï¼š

```python
# åœ¨ backend/store.py ä¸­æ·»åŠ æ•°æ®åº“æ”¯æŒ
import psycopg2
from sqlalchemy import create_engine

# æ•°æ®åº“è¿æ¥
DATABASE_URL = "postgresql://user:password@localhost/timeseries_db"
engine = create_engine(DATABASE_URL)
```

### ç¼“å­˜é…ç½®

ä½¿ç”¨ Redis è¿›è¡Œç¼“å­˜ï¼š

```python
import redis

# Redis è¿æ¥
redis_client = redis.Redis(host='localhost', port=6379, db=0)
```

### ç›‘æ§é…ç½®

#### Prometheus ç›‘æ§

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'timeseries-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: /metrics
    scrape_interval: 15s
```

#### Grafana ä»ªè¡¨æ¿

åˆ›å»º Grafana ä»ªè¡¨æ¿ç›‘æ§ï¼š
- ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
- æ¨¡å‹è®­ç»ƒçŠ¶æ€
- é¢„æµ‹å‡†ç¡®ç‡
- API å“åº”æ—¶é—´

### æ—¥å¿—é…ç½®

```python
# åœ¨ backend/app.py ä¸­é…ç½®æ—¥å¿—
import logging
from logging.handlers import RotatingFileHandler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(name)s %(message)s',
    handlers=[
        RotatingFileHandler('logs/app.log', maxBytes=10485760, backupCount=5),
        logging.StreamHandler()
    ]
)
```

## ğŸ”’ å®‰å…¨é…ç½®

### HTTPS é…ç½®

ä½¿ç”¨ Let's Encrypt è·å– SSL è¯ä¹¦ï¼š

```bash
# å®‰è£… certbot
sudo apt-get install certbot python3-certbot-nginx

# è·å–è¯ä¹¦
sudo certbot --nginx -d yourdomain.com
```

### é˜²ç«å¢™é…ç½®

```bash
# UFW é˜²ç«å¢™é…ç½®
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable
```

### API è®¤è¯

æ·»åŠ  JWT è®¤è¯ï¼š

```python
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer
import jwt

security = HTTPBearer()

def verify_token(token: str = Depends(security)):
    try:
        payload = jwt.decode(token.credentials, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.PyJWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials"
        )
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### è´Ÿè½½å‡è¡¡

ä½¿ç”¨ Nginx è¿›è¡Œè´Ÿè½½å‡è¡¡ï¼š

```nginx
upstream backend {
    server backend1:8000;
    server backend2:8000;
    server backend3:8000;
}
```

### æ•°æ®åº“ä¼˜åŒ–

```sql
-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_tasks_user ON tasks(user);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_models_user ON models(user);
```

### ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_model_predictions(model_id: str):
    # ç¼“å­˜æ¨¡å‹é¢„æµ‹ç»“æœ
    pass
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç«¯å£å†²çª**
   ```bash
   # æ£€æŸ¥ç«¯å£å ç”¨
   netstat -tulpn | grep :8000
   lsof -i :8000
   ```

2. **å†…å­˜ä¸è¶³**
   ```bash
   # æ£€æŸ¥å†…å­˜ä½¿ç”¨
   free -h
   top -p $(pgrep -f "python app.py")
   ```

3. **ç£ç›˜ç©ºé—´ä¸è¶³**
   ```bash
   # æ£€æŸ¥ç£ç›˜ç©ºé—´
   df -h
   du -sh logs/ models/
   ```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep ERROR logs/app.log

# æŸ¥çœ‹è®¿é—®æ—¥å¿—
tail -f logs/access.log

# åˆ†ææ€§èƒ½
grep "slow query" logs/app.log
```

### å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
curl http://localhost:8000/stats

# æ£€æŸ¥ Prometheus è¿æ¥
curl http://localhost:8000/api/data/metrics/test
```

## ğŸ“ˆ æ‰©å±•éƒ¨ç½²

### æ°´å¹³æ‰©å±•

```yaml
# docker-compose.yml
services:
  backend:
    deploy:
      replicas: 3
    environment:
      - WORKER_ID=${HOSTNAME}
```

### å‚ç›´æ‰©å±•

```yaml
# å¢åŠ èµ„æºé™åˆ¶
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
```

## ğŸ”„ æ›´æ–°éƒ¨ç½²

### æ»šåŠ¨æ›´æ–°

```bash
# æ›´æ–°é•œåƒ
docker-compose pull

# æ»šåŠ¨æ›´æ–°
docker-compose up -d --no-deps backend
```

### è“ç»¿éƒ¨ç½²

```bash
# éƒ¨ç½²æ–°ç‰ˆæœ¬åˆ°ç»¿è‰²ç¯å¢ƒ
docker-compose -f docker-compose.green.yml up -d

# åˆ‡æ¢æµé‡
# æ›´æ–°è´Ÿè½½å‡è¡¡å™¨é…ç½®

# åœæ­¢è“è‰²ç¯å¢ƒ
docker-compose -f docker-compose.blue.yml down
```

## ğŸ“ æ”¯æŒ

å¦‚æœ‰éƒ¨ç½²é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
2. æ£€æŸ¥é…ç½®æ–‡ä»¶
3. éªŒè¯ç½‘ç»œè¿æ¥
4. æäº¤ Issue
5. è”ç³»æŠ€æœ¯æ”¯æŒ

---

**æ³¨æ„**: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰è¯·è¿›è¡Œå……åˆ†æµ‹è¯•å’Œå®‰å…¨è¯„ä¼°ã€‚
